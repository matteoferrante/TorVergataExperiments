{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VQ VAE on CelebA\n",
    "Training model and PixelCNN Sampler\n",
    "\n",
    "Phase 1: Train VQVAE\n",
    "\n",
    "Phase 2: Train PixelCNN\n",
    "\n",
    "Phase 3: Sample images\n",
    "\n",
    "\n",
    "Note: After some attemps I see that the model produce images a little bit blurry to i chose to make it deeper\n",
    "\n",
    "## Phase 1: Train The variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from classes.VQVAE import VQVAE\n",
    "from classes.PixelCNN import PixelCNN,TfDistPixelCNN\n",
    "from utils.callbacks import WandbImagesVQVAE, Save_VQVAE_Weights, Save_PixelCNN_Weights\n",
    "from utils.functions import  map_vqvae_weights,pixelcnn_sample_vqvae\n",
    "from imutils import build_montages\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from tensorflow.data import AUTOTUNE\n",
    "\n",
    "import argparse\n",
    "from os.path import join as opj\n",
    "from imutils import paths\n",
    "import tqdm\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#set the first GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "print(os.environ.get(\"CUDA_VISIBLE_DEVICES\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "#phase=\"VQ_VAE_Training\"          #change\n",
    "phase=\"PixelCNN_Training\"\n",
    "\n",
    "config={\"dataset\":\"celebA\", \"type\":\"VQ-VAE\",\"phase\":phase}\n",
    "\n",
    "images_dir=r\"C:\\Users\\matte\\Dataset\\tor_vergata\\Dataset\\Img\\img_align_celeba\" #local\n",
    "images_dir=r\"/home/matteo/NeuroGEN/Dataset/Img/img_align_celeba\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 256\n",
    "EPOCHS=240\n",
    "INIT_LR=5e-5\n",
    "\n",
    "config[\"BS\"]=BS\n",
    "config[\"EPOCHS\"]=EPOCHS\n",
    "config[\"INIT_LR\"]=INIT_LR\n",
    "config[\"nota\"]=\"DGX\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(imagePath):\n",
    "    # read the image from disk, decode it, resize it, and scale the\n",
    "    # pixels intensities to the range [0, 1]\n",
    "    image = tf.io.read_file(imagePath)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (128, 128)) / 255.0\n",
    "\n",
    "    #eventually load other information like attributes here\n",
    "    \n",
    "    # return the image and the extra info\n",
    "    \n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading image paths...\n",
      "[TRAINING]\t 138545\n",
      "[VALIDATION]\t 17318\n",
      "[TEST]\t\t 17319\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading image paths...\")\n",
    "imagePaths = list(paths.list_images(images_dir))\n",
    "\n",
    "\n",
    "train_len=int(0.8*len(imagePaths))\n",
    "val_len=int(0.1*len(imagePaths))\n",
    "test_len=int(0.1*len(imagePaths))\n",
    "\n",
    "train_imgs=imagePaths[:train_len]                                #      80% for training\n",
    "val_imgs=imagePaths[train_len:train_len+val_len]                 #      10% for validation\n",
    "test_imgs=imagePaths[train_len+val_len:]                         #      10% for testing\n",
    "\n",
    "print(f\"[TRAINING]\\t {len(train_imgs)}\\n[VALIDATION]\\t {len(val_imgs)}\\n[TEST]\\t\\t {len(test_imgs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 14:36:53.239416: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-14 14:36:53.722178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79131 MB memory:  -> device: 0, name: NVIDIA A100-SXM-80GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "#TRAINING \n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "train_dataset = (train_dataset\n",
    "    .shuffle(1024)\n",
    "    .map(load_images, num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .repeat()\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "ts=len(train_imgs)//BS\n",
    "\n",
    "##VALIDATION\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(val_imgs)\n",
    "val_dataset = (val_dataset\n",
    "    .shuffle(1024)\n",
    "    .map(load_images, num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .repeat()\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "vs=len(val_imgs)//BS\n",
    "\n",
    "## TEST\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
    "test_dataset = (test_dataset\n",
    "    .shuffle(1024)\n",
    "    .map(load_images, num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training VQ_VAE Model\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image_input (InputLayer)    [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv_res_block (ConvResBloc  (None, 64, 64, 64)       80320     \n",
      " k)                                                              \n",
      "                                                                 \n",
      " conv_res_block_1 (ConvResBl  (None, 32, 32, 128)      386560    \n",
      " ock)                                                            \n",
      "                                                                 \n",
      " conv_res_block_2 (ConvResBl  (None, 16, 16, 256)      1543168   \n",
      " ock)                                                            \n",
      "                                                                 \n",
      " conv_res_block_3 (ConvResBl  (None, 8, 8, 256)        4334080   \n",
      " ock)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 8, 8, 512)         131584    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,475,712\n",
      "Trainable params: 6,470,848\n",
      "Non-trainable params: 4,864\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " latent_input (InputLayer)   [(None, 8, 8, 512)]       0         \n",
      "                                                                 \n",
      " conv_transpose_res_block (C  (None, 16, 16, 256)      4923904   \n",
      " onvTransposeResBlock)                                           \n",
      "                                                                 \n",
      " conv_transpose_res_block_1   (None, 32, 32, 256)      1838080   \n",
      " (ConvTransposeResBlock)                                         \n",
      "                                                                 \n",
      " conv_transpose_res_block_2   (None, 64, 64, 128)      607744    \n",
      " (ConvTransposeResBlock)                                         \n",
      "                                                                 \n",
      " conv_transpose_res_block_3   (None, 128, 128, 64)     152320    \n",
      " (ConvTransposeResBlock)                                         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 128, 128, 3)      1731      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,523,779\n",
      "Trainable params: 7,518,915\n",
      "Non-trainable params: 4,864\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(f\"[INFO] Training VQ_VAE Model\")\n",
    "\n",
    "encoder_architecture=[(1,64),(1,128),(1,256),(3,256)]\n",
    "decoder_architecture=[(3,256),(1,256),(1,128),(1,64)]\n",
    "input_shape=(128,128,3)\n",
    "latent_dim=512\n",
    "num_embeddings=256\n",
    "\n",
    "\n",
    "config[\"encoder_architecture\"]=encoder_architecture\n",
    "config[\"decoder_architecture\"]=decoder_architecture\n",
    "config[\"latent_dim\"]=latent_dim\n",
    "config[\"num_embeddings\"]=num_embeddings\n",
    "config[\"input_shape\"]=input_shape\n",
    "\n",
    "g=VQVAE(input_shape,latent_dim=latent_dim,num_embeddings=num_embeddings,train_variance=4,encoder_architecture=encoder_architecture,decoder_architecture=decoder_architecture)\n",
    "\n",
    "print(g.encoder.summary())\n",
    "\n",
    "print(g.decoder.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Train the VQ-VAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatteoferrante\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/matteoferrante/TorVergataExperiment-Generative/runs/119lyngs\" target=\"_blank\">fast-firebrand-454</a></strong> to <a href=\"https://wandb.ai/matteoferrante/TorVergataExperiment-Generative\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/matteoferrante/TorVergataExperiment-Generative/runs/119lyngs?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fa1cee5a9d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"TorVergataExperiment-Generative\",config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models/vqvae_celeba\",exist_ok=True)\n",
    "model_check= Save_VQVAE_Weights(\"models/vqvae_celeba\")\n",
    "\n",
    "\n",
    "\n",
    "es=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    min_delta=0,\n",
    "    patience=8,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "\n",
    "callbacks=[\n",
    "    WandbImagesVQVAE(test_dataset,sample=False),\n",
    "    WandbCallback(),\n",
    "    model_check,\n",
    "    es,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPILE AND TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.compile(keras.optimizers.Adam(INIT_LR))\n",
    "g.build(input_shape=(None,*input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "Epoch 1/240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 14:37:58.440055: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8300\n",
      "2021-12-14 14:38:00.186729: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - ETA: 0s - loss: 0.0689 - reconstruction_loss: 0.0105 - vqvae_loss: 0.0535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 14:41:00.760040: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 187s 327ms/step - loss: 0.0689 - reconstruction_loss: 0.0105 - vqvae_loss: 0.0536 - val_val_reconstruction_loss: 0.0059\n",
      "Epoch 2/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0395 - reconstruction_loss: 0.0051 - vqvae_loss: 0.0343"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 14:43:53.556045: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 173s 319ms/step - loss: 0.0395 - reconstruction_loss: 0.0051 - vqvae_loss: 0.0343 - val_val_reconstruction_loss: 0.0131\n",
      "Epoch 3/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0291 - reconstruction_loss: 0.0051 - vqvae_loss: 0.0231"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 14:46:45.213447: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 317ms/step - loss: 0.0291 - reconstruction_loss: 0.0051 - vqvae_loss: 0.0231 - val_val_reconstruction_loss: 0.0047\n",
      "Epoch 4/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0215 - reconstruction_loss: 0.0044 - vqvae_loss: 0.0171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 14:49:37.215653: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0215 - reconstruction_loss: 0.0044 - vqvae_loss: 0.0171 - val_val_reconstruction_loss: 0.0045\n",
      "Epoch 5/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0186 - reconstruction_loss: 0.0039 - vqvae_loss: 0.0145"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 14:52:28.860958: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 317ms/step - loss: 0.0186 - reconstruction_loss: 0.0039 - vqvae_loss: 0.0145 - val_val_reconstruction_loss: 0.0037\n",
      "Epoch 6/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0145 - reconstruction_loss: 0.0035 - vqvae_loss: 0.0110"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 14:55:20.998375: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0145 - reconstruction_loss: 0.0035 - vqvae_loss: 0.0110 - val_val_reconstruction_loss: 0.0034\n",
      "Epoch 7/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0120 - reconstruction_loss: 0.0032 - vqvae_loss: 0.0087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 14:58:13.350795: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 319ms/step - loss: 0.0120 - reconstruction_loss: 0.0032 - vqvae_loss: 0.0087 - val_val_reconstruction_loss: 0.0032\n",
      "Epoch 8/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0099 - reconstruction_loss: 0.0031 - vqvae_loss: 0.0068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:01:05.518511: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0099 - reconstruction_loss: 0.0031 - vqvae_loss: 0.0068 - val_val_reconstruction_loss: 0.0031\n",
      "Epoch 9/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0094 - reconstruction_loss: 0.0030 - vqvae_loss: 0.0064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:03:57.915124: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 319ms/step - loss: 0.0094 - reconstruction_loss: 0.0030 - vqvae_loss: 0.0064 - val_val_reconstruction_loss: 0.0030\n",
      "Epoch 10/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0091 - reconstruction_loss: 0.0029 - vqvae_loss: 0.0061"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:06:50.033604: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0091 - reconstruction_loss: 0.0029 - vqvae_loss: 0.0061 - val_val_reconstruction_loss: 0.0029\n",
      "Epoch 11/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0087 - reconstruction_loss: 0.0028 - vqvae_loss: 0.0059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:09:42.011515: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0087 - reconstruction_loss: 0.0028 - vqvae_loss: 0.0059 - val_val_reconstruction_loss: 0.0029\n",
      "Epoch 12/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0085 - reconstruction_loss: 0.0028 - vqvae_loss: 0.0057"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:12:34.113229: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0085 - reconstruction_loss: 0.0028 - vqvae_loss: 0.0057 - val_val_reconstruction_loss: 0.0028\n",
      "Epoch 13/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0081 - reconstruction_loss: 0.0027 - vqvae_loss: 0.0054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:15:25.982149: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0081 - reconstruction_loss: 0.0027 - vqvae_loss: 0.0054 - val_val_reconstruction_loss: 0.0027\n",
      "Epoch 14/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0078 - reconstruction_loss: 0.0026 - vqvae_loss: 0.0051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:18:18.005121: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0078 - reconstruction_loss: 0.0026 - vqvae_loss: 0.0051 - val_val_reconstruction_loss: 0.0026\n",
      "Epoch 15/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0075 - reconstruction_loss: 0.0026 - vqvae_loss: 0.0049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:21:10.160118: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0075 - reconstruction_loss: 0.0026 - vqvae_loss: 0.0049 - val_val_reconstruction_loss: 0.0026\n",
      "Epoch 16/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0073 - reconstruction_loss: 0.0025 - vqvae_loss: 0.0048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:24:02.197406: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0073 - reconstruction_loss: 0.0025 - vqvae_loss: 0.0048 - val_val_reconstruction_loss: 0.0026\n",
      "Epoch 17/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0072 - reconstruction_loss: 0.0025 - vqvae_loss: 0.0048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:26:54.457239: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0072 - reconstruction_loss: 0.0025 - vqvae_loss: 0.0048 - val_val_reconstruction_loss: 0.0025\n",
      "Epoch 18/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0072 - reconstruction_loss: 0.0024 - vqvae_loss: 0.0047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:29:46.334623: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0072 - reconstruction_loss: 0.0024 - vqvae_loss: 0.0047 - val_val_reconstruction_loss: 0.0025\n",
      "Epoch 19/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0072 - reconstruction_loss: 0.0024 - vqvae_loss: 0.0048"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:32:38.177358: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0072 - reconstruction_loss: 0.0024 - vqvae_loss: 0.0048 - val_val_reconstruction_loss: 0.0025\n",
      "Epoch 20/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0071 - reconstruction_loss: 0.0024 - vqvae_loss: 0.0047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:35:30.272575: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0071 - reconstruction_loss: 0.0024 - vqvae_loss: 0.0047 - val_val_reconstruction_loss: 0.0024\n",
      "Epoch 21/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0070 - reconstruction_loss: 0.0023 - vqvae_loss: 0.0046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:38:22.507930: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0070 - reconstruction_loss: 0.0023 - vqvae_loss: 0.0046 - val_val_reconstruction_loss: 0.0024\n",
      "Epoch 22/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0069 - reconstruction_loss: 0.0023 - vqvae_loss: 0.0045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:41:14.518801: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0069 - reconstruction_loss: 0.0023 - vqvae_loss: 0.0045 - val_val_reconstruction_loss: 0.0023\n",
      "Epoch 23/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0068 - reconstruction_loss: 0.0023 - vqvae_loss: 0.0045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:44:06.365321: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0068 - reconstruction_loss: 0.0023 - vqvae_loss: 0.0045 - val_val_reconstruction_loss: 0.0023\n",
      "Epoch 24/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0068 - reconstruction_loss: 0.0023 - vqvae_loss: 0.0046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:46:58.556819: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0068 - reconstruction_loss: 0.0023 - vqvae_loss: 0.0046 - val_val_reconstruction_loss: 0.0023\n",
      "Epoch 25/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0068 - reconstruction_loss: 0.0022 - vqvae_loss: 0.0046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:49:50.409063: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0068 - reconstruction_loss: 0.0022 - vqvae_loss: 0.0046 - val_val_reconstruction_loss: 0.0023\n",
      "Epoch 26/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0069 - reconstruction_loss: 0.0022 - vqvae_loss: 0.0046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:52:42.562839: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0069 - reconstruction_loss: 0.0022 - vqvae_loss: 0.0046 - val_val_reconstruction_loss: 0.0023\n",
      "Epoch 27/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0068 - reconstruction_loss: 0.0022 - vqvae_loss: 0.0046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:55:34.482417: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0068 - reconstruction_loss: 0.0022 - vqvae_loss: 0.0046 - val_val_reconstruction_loss: 0.0022\n",
      "Epoch 28/240\n",
      "541/541 [==============================] - ETA: 0s - loss: 0.0068 - reconstruction_loss: 0.0022 - vqvae_loss: 0.0046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:58:26.256615: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 172s 318ms/step - loss: 0.0068 - reconstruction_loss: 0.0022 - vqvae_loss: 0.0046 - val_val_reconstruction_loss: 0.0022\n",
      "Epoch 29/240\n",
      " 46/541 [=>............................] - ETA: 2:30 - loss: 0.0069 - reconstruction_loss: 0.0022 - vqvae_loss: 0.0047"
     ]
    }
   ],
   "source": [
    "g.fit(train_dataset,validation_data=val_dataset,steps_per_epoch=ts,validation_steps=vs,epochs=EPOCHS,callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Train the PixelCNN sampler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_models_weights(model_dir):\n",
    "    files=os.listdir(model_dir)\n",
    "    d={}\n",
    "    for f in files:\n",
    "        if \"encoder\" in f:\n",
    "            d[\"encoder\"]=opj(model_dir,f)\n",
    "        elif (\"generator\" in f) or (\"decoder\" in f):\n",
    "            d[\"decoder\"]=opj(model_dir,f)\n",
    "        elif \"embeddings\" in f:\n",
    "            d[\"embeddings\"]=opj(model_dir,f)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model=VQVAE((28,28,1),latent_dim=16,num_embeddings=128,train_variance=4)\n",
    "\n",
    "weights=map_models_weights(\"models/vqvae_celeba\")\n",
    "\n",
    "print(weights)\n",
    "g.load_weights(weights[\"encoder\"],weights[\"embeddings\"],weights[\"decoder\"])\n",
    "\n",
    "\n",
    "BS=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using smaller batch size while predict\n",
    "\n",
    "A memory bug?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "train_dataset = (train_dataset\n",
    "    .shuffle(1024)\n",
    "    .map(load_images, num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "ts=len(train_imgs)//BS\n",
    "\n",
    "##VALIDATION\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(val_imgs)\n",
    "val_dataset = (val_dataset\n",
    "    .shuffle(1024)\n",
    "    .map(load_images, num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_outputs=[]\n",
    "\n",
    "for batch in tqdm.tqdm(train_dataset):\n",
    "    encoded_outputs.append(g.encoder.predict_on_batch(batch))\n",
    "\n",
    "#encoded_outputs = g.encoder.predict(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_outputs[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook_indices=[]\n",
    "for b in tqdm.tqdm(range(len(train_dataset))):\n",
    "\n",
    "    #flat the outputs\n",
    "    batch_encoded=np.array(encoded_outputs[b])\n",
    "    flat_enc_outputs=batch_encoded.reshape(-1,batch_encoded.shape[-1])\n",
    "    code_index=g.vq_layer.get_code_indices(flat_enc_outputs).numpy()\n",
    "    codebook_indices.append(list(code_index))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook_indices = list(itertools.chain.from_iterable(codebook_indices))\n",
    "codebook_indices = np.array(codebook_indices)\n",
    "print(codebook_indices.shape)\n",
    "\n",
    "square_dim=batch_encoded.shape[1]\n",
    "\n",
    "codebook_indices = codebook_indices.reshape(-1,square_dim,square_dim)\n",
    "print(f\"Shape of the training data for PixelCNN: {codebook_indices.shape}\")\n",
    "\n",
    "input_shape=(codebook_indices.shape[1],codebook_indices.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_cnn = PixelCNN(input_dim=input_shape, n_embeddings=256, n_residual=8, n_convlayer=4)\n",
    "opt = keras.optimizers.Adam(3e-4)\n",
    "pixel_cnn.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=opt,metrics=\"accuracy\")\n",
    "\n",
    "wandb.init(project=\"TorVergataExperiment-Generative\",config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=15,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "callbacks = [WandbCallback(), es]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_cnn_dir=\"models/vqvae_celeba/pixelcnn\"\n",
    "os.makedirs(pixel_cnn_dir,exist_ok=True)\n",
    "\n",
    "pixel_cnn.save_dict(opj(pixel_cnn_dir,\"dict.json\"))\n",
    "\n",
    "pixel_cnn.fit(codebook_indices, codebook_indices, batch_size=BS, validation_split=0.1, epochs=30,\n",
    "              callbacks=callbacks)\n",
    "pixel_cnn.model.save_weights(opj(pixel_cnn_dir,\"pixelcnn_vqvae_celeba_weights.h5\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Sample the VQ VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=map_models_weights(\"models/vqvae_celeba\")\n",
    "\n",
    "print(weights)\n",
    "g.load_weights(weights[\"encoder\"],weights[\"embeddings\"],weights[\"decoder\"])\n",
    "\n",
    "BS=64\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_cnn_dir=\"models/vqvae_celeba/pixelcnn\"\n",
    "\n",
    "\n",
    "config=glob.glob(opj(pixel_cnn_dir,\"*.json\"))[0]\n",
    "weights=glob.glob(opj(pixel_cnn_dir,\"*.h5\"))[0]\n",
    "\n",
    "print(f\"[CONFIG] PixelCNN {config}\")\n",
    "f=open(config,\"r\")\n",
    "\n",
    "config=json.load(f)\n",
    "\n",
    "input_dim=config[\"input_dim\"]\n",
    "n_emb=config[\"num_embeddings\"]\n",
    "n_res=config[\"n_residual\"]\n",
    "n_conv=config[\"n_convlayer\"]\n",
    "ksize=config[\"ksize\"]\n",
    "p=PixelCNN(input_dim=input_dim,n_embeddings=n_emb,n_residual=n_res,n_convlayer=n_conv,ksize=ksize)\n",
    "\n",
    "p.model.load_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_samples=pixelcnn_sample_vqvae(100,p.model,g)\n",
    "\n",
    "images = generated_samples * 255.\n",
    "#images = np.repeat(images, 3, axis=-1)\n",
    "vis = build_montages(images, (128, 128), (10, 10))[0]\n",
    "\n",
    "log = {f\"image_sampled\": wandb.Image(vis)}\n",
    "wandb.log(log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
