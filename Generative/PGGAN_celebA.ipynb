{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c7ced4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import argparse\n",
    "from classes.PGGAN import PGGAN\n",
    "from utils.callbacks import WandbImagesPGGAN\n",
    "import wandb\n",
    "import tensorflow.keras as keras\n",
    "from os.path import join as opj\n",
    "from wandb.keras import WandbCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "036ff2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatteoferrante\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">vague-breeze-450</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/matteoferrante/TorVergataExperiment-Generative\" target=\"_blank\">https://wandb.ai/matteoferrante/TorVergataExperiment-Generative</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/matteoferrante/TorVergataExperiment-Generative/runs/2paj5tiy\" target=\"_blank\">https://wandb.ai/matteoferrante/TorVergataExperiment-Generative/runs/2paj5tiy</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\matte\\PycharmProjects\\TorVergataExperiments\\Generative\\wandb\\run-20211213_153114-2paj5tiy</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(2paj5tiy)</h1><iframe src=\"https://wandb.ai/matteoferrante/TorVergataExperiment-Generative/runs/2paj5tiy\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x21cdbb2ef40>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wandb.login()\n",
    "\n",
    "checkpoint_path= \"models/PGGAN_celebA\"\n",
    "config={\"dataset\":\"celebA\", \"type\":\"PG-GAN\"}\n",
    "\n",
    "wandb.init(project=\"TorVergataExperiment-Generative\",config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a2544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BS_list = [256,128,64,32]\n",
    "\n",
    "BS=BS_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3892e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NOISE_DIM = 128\n",
    "# Set the number of batches, epochs and steps for trainining.\n",
    "# Look 800k images(16x50x1000) per each lavel\n",
    "EPOCHS_PER_RES = 16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcc307a",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49023fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(imagePath):\n",
    "    # read the image from disk, decode it, resize it, and scale the\n",
    "    # pixels intensities to the range [0, 1]\n",
    "    image = tf.io.read_file(imagePath)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (128, 128)) / 255.0\n",
    "\n",
    "    #eventually load other information like attributes here\n",
    "    \n",
    "    # return the image and the extra info\n",
    "    \n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19961f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INIT\n",
    "\n",
    "def resize(img,target_size=(4,4)):\n",
    "    return tf.image.resize(img,target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] loading image paths...\")\n",
    "imagePaths = list(paths.list_images(images_dir))\n",
    "\n",
    "\n",
    "train_len=int(0.8*len(imagePaths))\n",
    "val_len=int(0.1*len(imagePaths))\n",
    "test_len=int(0.1*len(imagePaths))\n",
    "\n",
    "train_imgs=imagePaths[:train_len]                                #      80% for training\n",
    "val_imgs=imagePaths[train_len:train_len+val_len]                 #      10% for validation\n",
    "test_imgs=imagePaths[train_len+val_len:]                         #      10% for testing\n",
    "\n",
    "print(f\"[TRAINING]\\t {len(train_imgs)}\\n[VALIDATION]\\t {len(val_imgs)}\\n[TEST]\\t\\t {len(test_imgs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466eba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING \n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "train_dataset = (train_dataset\n",
    "    .shuffle(1024)\n",
    "    .map(resize)\n",
    "    .cache()\n",
    "    .repeat()\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "ts=len(train_imgs)//BS\n",
    "\n",
    "##VALIDATION\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(val_imgs)\n",
    "val_dataset = (val_dataset\n",
    "    .shuffle(1024)\n",
    "    .map(resize)\n",
    "    .cache()\n",
    "    .repeat()\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "vs=len(val_imgs)//BS\n",
    "\n",
    "## TEST\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
    "test_dataset = (test_dataset\n",
    "    .shuffle(1024)\n",
    "    .map(resize)\n",
    "    .cache()\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e124eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the optimizer for both networks\n",
    "# learning_rate will be equalized per each layers by the WeightScaling scheme\n",
    "generator_optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.0, beta_2=0.99, epsilon=1e-8)\n",
    "discriminator_optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.0, beta_2=0.99, epsilon=1e-8)\n",
    "\n",
    "pgan = PGGAN(\n",
    "    latent_dim = NOISE_DIM,\n",
    "    d_steps = 1,\n",
    ")\n",
    "\n",
    "callbacks=[WandbImagesPGGAN(),WandbCallback()]\n",
    "\n",
    "pgan.compile(\n",
    "    d_optimizer=discriminator_optimizer,\n",
    "    g_optimizer=generator_optimizer,\n",
    ")\n",
    "\n",
    "os.makedirs(checkpoint_path,exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65157bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(checkpoint_path,exist_ok=True)\n",
    "# Start training the initial generator and discriminator\n",
    "pgan.fit(train_dataset, steps_per_epoch = ts, epochs = EPOCHS_PER_RES, callbacks=callbacks)\n",
    "pgan.save_weights(opj(checkpoint_path, f\"checkpoint_path_ndepth_0_weights_celebA.h5\"))\n",
    "\n",
    "tf.keras.utils.plot_model(pgan.generator, to_file=opj(checkpoint_path,f'generator_{pgan.n_depth}.png'), show_shapes=True)\n",
    "tf.keras.utils.plot_model(pgan.discriminator, to_file=opj(checkpoint_path,f'discriminator_{pgan.n_depth}.png'), show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c513bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train faded-in / stabilized generators and discriminators\n",
    "for n_depth in range(1, 6):\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"[INFO] Fading phase for {n_depth}\")\n",
    "    # Set current level(depth)\n",
    "    pgan.n_depth = n_depth\n",
    "\n",
    "    new_dim=2**(n_depth)*4\n",
    "    new_dim=(new_dim,new_dim)\n",
    "\n",
    "    ##dataset redefinition\n",
    "    BS=BS_list[n_depth]\n",
    "    ts = len(x_train) // BS\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BS).repeat().map(lambda  x: resize(x,new_dim))\n",
    "\n",
    "    #enlarge network\n",
    "\n",
    "    pgan.fade_in_generator()\n",
    "    pgan.fade_in_discriminator()\n",
    "\n",
    "    # Draw fade in generator and discriminator\n",
    "    tf.keras.utils.plot_model(pgan.generator, to_file=opj(checkpoint_path,f'generator_{pgan.n_depth}.png'), show_shapes=True)\n",
    "    tf.keras.utils.plot_model(pgan.discriminator, to_file=opj(checkpoint_path,f'discriminator_{pgan.n_depth}.png'), show_shapes=True)\n",
    "\n",
    "    pgan.compile(\n",
    "      d_optimizer=discriminator_optimizer,\n",
    "      g_optimizer=generator_optimizer,\n",
    "    )\n",
    "    # Train fade in generator and discriminator\n",
    "    pgan.fit(train_dataset, steps_per_epoch=ts, epochs=EPOCHS_PER_RES, callbacks=callbacks)\n",
    "\n",
    "    pgan.generator.save_weights(opj(checkpoint_path, f\"generator_ndepth_{n_depth}_weights_cifar.h5\"))\n",
    "    pgan.discriminator.save_weights(opj(checkpoint_path, f\"discriminator_ndepth_{n_depth}_weights_cifar.h5\"))\n",
    "\n",
    "    try:\n",
    "        pgan.save_weights(opj(checkpoint_path, f\"checkpoint_path_ndepth_{n_depth}_weights_cifar.ckpt\"),save_format=\"tf\")\n",
    "    except:\n",
    "        print(\"[WARNING] Could not save weights!\")\n",
    "\n",
    "\n",
    "    print(f\"[INFO] Stabilizing phase for {n_depth}\")\n",
    "    pgan.stabilize_generator()\n",
    "    pgan.stabilize_discriminator()\n",
    "\n",
    "    # Draw fade in generator and discriminator\n",
    "    tf.keras.utils.plot_model(pgan.generator, to_file=opj(checkpoint_path,f'generator_{pgan.n_depth}_stabilized.png'), show_shapes=True)\n",
    "    tf.keras.utils.plot_model(pgan.discriminator, to_file=opj(checkpoint_path,f'discriminator_{pgan.n_depth}_stabilized.png'), show_shapes=True)\n",
    "\n",
    "    pgan.compile(d_optimizer=discriminator_optimizer,g_optimizer=generator_optimizer,)\n",
    "    # Train stabilized generator and discriminator\n",
    "    pgan.fit(train_dataset, steps_per_epoch = ts, epochs = EPOCHS_PER_RES, callbacks=callbacks)\n",
    "    pgan.generator.save_weights(opj(checkpoint_path, f\"generator_stabilized_ndepth_{n_depth}_weights_cifar.h5\"))\n",
    "    pgan.discriminator.save_weights(opj(checkpoint_path, f\"discriminator_stabilized_ndepth_{n_depth}_weights_cifar.h5\"))\n",
    "\n",
    "    try:\n",
    "        pgan.save_weights(opj(checkpoint_path, f\"checkpoint_path_stabilized_ndepth_{n_depth}_weights_cifar.ckpt\"), save_format=\"tf\")\n",
    "    except:\n",
    "        print(\"[WARNING] Could not save weights!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
