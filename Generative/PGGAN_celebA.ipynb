{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e5a6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import argparse\n",
    "from classes.PGGAN import PGGAN\n",
    "from utils.callbacks import WandbImagesPGGAN\n",
    "import wandb\n",
    "import tensorflow.keras as keras\n",
    "from os.path import join as opj\n",
    "from wandb.keras import WandbCallback\n",
    "from imutils import paths\n",
    "from tensorflow.data import AUTOTUNE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875a2fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31e1de48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatteoferrante\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "/usr/local/lib/python3.8/dist-packages/IPython/html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/matteoferrante/TorVergataExperiment-Generative/runs/1msxxuxf\" target=\"_blank\">firm-forest-459</a></strong> to <a href=\"https://wandb.ai/matteoferrante/TorVergataExperiment-Generative\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "wandb.login()\n",
    "\n",
    "checkpoint_path= \"models/PGGAN_celebA\"\n",
    "config={\"dataset\":\"celebA\", \"type\":\"PG-GAN\"}\n",
    "config[\"nota\"]=\"DGX\"\n",
    "wandb.init(project=\"TorVergataExperiment-Generative\",config=config)\n",
    "\n",
    "images_dir=r\"/home/matteo/NeuroGEN/Dataset/Img/img_align_celeba\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdf4c171",
   "metadata": {},
   "outputs": [],
   "source": [
    "BS_list = [512,512,256,128,64,32]\n",
    "\n",
    "BS=BS_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17755670",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NOISE_DIM = 256\n",
    "# Set the number of batches, epochs and steps for trainining.\n",
    "# Look 800k images(16x50x1000) per each lavel\n",
    "EPOCHS_PER_RES = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2838f8e9",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ad48938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(imagePath):\n",
    "    # read the image from disk, decode it, resize it, and scale the\n",
    "    # pixels intensities to the range [0, 1]\n",
    "    image = tf.io.read_file(imagePath)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (128, 128)) / 255.0\n",
    "\n",
    "    #eventually load other information like attributes here\n",
    "    \n",
    "    # return the image and the extra info\n",
    "    \n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "917cd2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INIT\n",
    "\n",
    "def read(img):\n",
    "    image = tf.io.read_file(img)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    return image\n",
    "\n",
    "def resize_and_normalize(img,target_size):\n",
    "    return tf.image.resize(img,target_size)/255.\n",
    "\n",
    "def resize(img,target_size=(4,4)):\n",
    "    image = tf.io.read_file(img)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    return tf.image.resize(image,target_size)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f50799f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading image paths...\n",
      "[TRAINING]\t 138545\n",
      "[VALIDATION]\t 17318\n",
      "[TEST]\t\t 17319\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading image paths...\")\n",
    "imagePaths = list(paths.list_images(images_dir))\n",
    "\n",
    "\n",
    "train_len=int(0.8*len(imagePaths))\n",
    "val_len=int(0.1*len(imagePaths))\n",
    "test_len=int(0.1*len(imagePaths))\n",
    "\n",
    "train_imgs=imagePaths[:train_len]                                #      80% for training\n",
    "val_imgs=imagePaths[train_len:train_len+val_len]                 #      10% for validation\n",
    "test_imgs=imagePaths[train_len+val_len:]                         #      10% for testing\n",
    "\n",
    "print(f\"[TRAINING]\\t {len(train_imgs)}\\n[VALIDATION]\\t {len(val_imgs)}\\n[TEST]\\t\\t {len(test_imgs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aace2427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING \n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "train_dataset = (train_dataset\n",
    "    .shuffle(1024)\n",
    "    .map(resize)\n",
    "    .cache()\n",
    "    .repeat()\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "ts=len(train_imgs)//BS\n",
    "\n",
    "##VALIDATION\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(val_imgs)\n",
    "val_dataset = (val_dataset\n",
    "    .shuffle(1024)\n",
    "    .map(resize)\n",
    "    .cache()\n",
    "    .repeat()\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "vs=len(val_imgs)//BS\n",
    "\n",
    "## TEST\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
    "test_dataset = (test_dataset\n",
    "    .shuffle(1024)\n",
    "    .map(resize)\n",
    "    .cache()\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d40cd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 256)]             0         \n",
      "                                                                 \n",
      " pixel_normalization (PixelN  (None, 256)              0         \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8192)              2097152   \n",
      "                                                                 \n",
      " weight_scaling_4 (WeightSca  (None, 8192)             0         \n",
      " ling)                                                           \n",
      "                                                                 \n",
      " bias_4 (Bias)               (None, 8192)              8192      \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 8192)              0         \n",
      "                                                                 \n",
      " pixel_normalization_1 (Pixe  (None, 8192)             0         \n",
      " lNormalization)                                                 \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 512)         4194304   \n",
      "                                                                 \n",
      " weight_scaling_5 (WeightSca  (None, 4, 4, 512)        0         \n",
      " ling)                                                           \n",
      "                                                                 \n",
      " bias_5 (Bias)               (None, 4, 4, 512)         512       \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " pixel_normalization_2 (Pixe  (None, 4, 4, 512)        0         \n",
      " lNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 4, 4, 512)         2359296   \n",
      "                                                                 \n",
      " weight_scaling_6 (WeightSca  (None, 4, 4, 512)        0         \n",
      " ling)                                                           \n",
      "                                                                 \n",
      " bias_6 (Bias)               (None, 4, 4, 512)         512       \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " pixel_normalization_3 (Pixe  (None, 4, 4, 512)        0         \n",
      " lNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 3)           1536      \n",
      "                                                                 \n",
      " weight_scaling_7 (WeightSca  (None, 4, 4, 3)          0         \n",
      " ling)                                                           \n",
      "                                                                 \n",
      " bias_7 (Bias)               (None, 4, 4, 3)           3         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 4, 4, 3)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,661,507\n",
      "Trainable params: 8,661,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the optimizer for both networks\n",
    "# learning_rate will be equalized per each layers by the WeightScaling scheme\n",
    "generator_optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.0, beta_2=0.99, epsilon=1e-8)\n",
    "discriminator_optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.0, beta_2=0.99, epsilon=1e-8)\n",
    "\n",
    "pgan = PGGAN(\n",
    "    latent_dim = NOISE_DIM,\n",
    "    d_steps = 1,\n",
    ")\n",
    "\n",
    "callbacks=[WandbImagesPGGAN(),WandbCallback()]\n",
    "\n",
    "pgan.compile(\n",
    "    d_optimizer=discriminator_optimizer,\n",
    "    g_optimizer=generator_optimizer,\n",
    ")\n",
    "\n",
    "os.makedirs(checkpoint_path,exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86ff2a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:11:37.732794: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2021-12-14 15:11:37.868658: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 16s 38ms/step - d_loss: -0.8435 - g_loss: 1.2336\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: -0.4925 - g_loss: -0.4942\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 8s 29ms/step - d_loss: -0.4655 - g_loss: -0.2741\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: -0.3270 - g_loss: 0.2009\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: -0.1676 - g_loss: 0.3189\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: -0.0903 - g_loss: 0.3525\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: -0.0924 - g_loss: 0.3153\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 8s 29ms/step - d_loss: -0.0656 - g_loss: 0.2658\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: -0.1116 - g_loss: 0.2767\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: -0.0972 - g_loss: 0.2783\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: -0.0593 - g_loss: 0.2402\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: -0.1034 - g_loss: 0.2554\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 8s 29ms/step - d_loss: -0.0877 - g_loss: 0.2449\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: -0.0892 - g_loss: 0.2389\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: -0.0821 - g_loss: 0.2257\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: -0.0835 - g_loss: 0.2166\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: -0.0809 - g_loss: 0.2087\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 8s 29ms/step - d_loss: -0.0490 - g_loss: 0.1755\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: -0.0593 - g_loss: 0.1879\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: -0.0307 - g_loss: 0.1655\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0126 - g_loss: 0.1019\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: -0.0037 - g_loss: 0.0972\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0226 - g_loss: 0.0747\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 8s 29ms/step - d_loss: 0.0320 - g_loss: 0.0720\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0128 - g_loss: 0.0794\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0358 - g_loss: 0.0773\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0502 - g_loss: 0.0768\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0464 - g_loss: 0.0794\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 8s 29ms/step - d_loss: 0.0428 - g_loss: 0.0647\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0249 - g_loss: 0.0702\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0450 - g_loss: 0.0594\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0342 - g_loss: 0.0669\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0432 - g_loss: 0.0572\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 8s 29ms/step - d_loss: 0.0497 - g_loss: 0.0666\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0377 - g_loss: 0.0522\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0317 - g_loss: 0.0630\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0292 - g_loss: 0.0579\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0282 - g_loss: 0.0496\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 8s 29ms/step - d_loss: 0.0273 - g_loss: 0.0551\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0233 - g_loss: 0.0469\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0221 - g_loss: 0.0422\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0200 - g_loss: 0.0438\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0220 - g_loss: 0.0386\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0221 - g_loss: 0.0409\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 8s 29ms/step - d_loss: 0.0214 - g_loss: 0.0392\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0228 - g_loss: 0.0347\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0263 - g_loss: 0.0375\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0197 - g_loss: 0.0327\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 8s 28ms/step - d_loss: 0.0222 - g_loss: 0.0383\n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 8s 29ms/step - d_loss: 0.0218 - g_loss: 0.0305\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(checkpoint_path,exist_ok=True)\n",
    "# Start training the initial generator and discriminator\n",
    "pgan.fit(train_dataset, steps_per_epoch = ts, epochs = EPOCHS_PER_RES, callbacks=callbacks)\n",
    "pgan.save_weights(opj(checkpoint_path, f\"checkpoint_path_ndepth_0_weights_celebA.h5\"))\n",
    "\n",
    "tf.keras.utils.plot_model(pgan.generator, to_file=opj(checkpoint_path,f'generator_{pgan.n_depth}.png'), show_shapes=True)\n",
    "tf.keras.utils.plot_model(pgan.discriminator, to_file=opj(checkpoint_path,f'discriminator_{pgan.n_depth}.png'), show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b361875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fading phase for 1\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " pixel_normalization (PixelNorm  (None, 256)         0           ['input_2[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 8192)         2097152     ['pixel_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " weight_scaling_4 (WeightScalin  (None, 8192)        0           ['dense_1[0][0]']                \n",
      " g)                                                                                               \n",
      "                                                                                                  \n",
      " bias_4 (Bias)                  (None, 8192)         8192        ['weight_scaling_4[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 8192)         0           ['bias_4[0][0]']                 \n",
      "                                                                                                  \n",
      " pixel_normalization_1 (PixelNo  (None, 8192)        0           ['leaky_re_lu_3[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 4, 4, 512)    0           ['pixel_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 4, 4, 512)    4194304     ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " weight_scaling_5 (WeightScalin  (None, 4, 4, 512)   0           ['conv2d_3[0][0]']               \n",
      " g)                                                                                               \n",
      "                                                                                                  \n",
      " bias_5 (Bias)                  (None, 4, 4, 512)    512         ['weight_scaling_5[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 4, 4, 512)    0           ['bias_5[0][0]']                 \n",
      "                                                                                                  \n",
      " pixel_normalization_2 (PixelNo  (None, 4, 4, 512)   0           ['leaky_re_lu_4[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 4, 4, 512)    2359296     ['pixel_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " weight_scaling_6 (WeightScalin  (None, 4, 4, 512)   0           ['conv2d_4[0][0]']               \n",
      " g)                                                                                               \n",
      "                                                                                                  \n",
      " bias_6 (Bias)                  (None, 4, 4, 512)    512         ['weight_scaling_6[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 4, 4, 512)    0           ['bias_6[0][0]']                 \n",
      "                                                                                                  \n",
      " pixel_normalization_3 (PixelNo  (None, 4, 4, 512)   0           ['leaky_re_lu_5[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 8, 8, 512)    0           ['pixel_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 8, 8, 512)    2359296     ['up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " weight_scaling_8 (WeightScalin  (None, 8, 8, 512)   0           ['conv2d_6[0][0]']               \n",
      " g)                                                                                               \n",
      "                                                                                                  \n",
      " bias_8 (Bias)                  (None, 8, 8, 512)    512         ['weight_scaling_8[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 8, 8, 512)    0           ['bias_8[0][0]']                 \n",
      "                                                                                                  \n",
      " pixel_normalization_4 (PixelNo  (None, 8, 8, 512)   0           ['leaky_re_lu_6[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 8, 8, 512)    2359296     ['pixel_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " weight_scaling_9 (WeightScalin  (None, 8, 8, 512)   0           ['conv2d_7[0][0]']               \n",
      " g)                                                                                               \n",
      "                                                                                                  \n",
      " bias_9 (Bias)                  (None, 8, 8, 512)    512         ['weight_scaling_9[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 8, 8, 512)    0           ['bias_9[0][0]']                 \n",
      "                                                                                                  \n",
      " pixel_normalization_5 (PixelNo  (None, 8, 8, 512)   0           ['leaky_re_lu_7[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              multiple             1536        ['up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 8, 8, 3)      1536        ['pixel_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " weight_scaling_7 (WeightScalin  multiple            0           ['conv2d_5[1][0]']               \n",
      " g)                                                                                               \n",
      "                                                                                                  \n",
      " weight_scaling_10 (WeightScali  (None, 8, 8, 3)     0           ['conv2d_8[0][0]']               \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " bias_7 (Bias)                  multiple             3           ['weight_scaling_7[1][0]']       \n",
      "                                                                                                  \n",
      " bias_10 (Bias)                 (None, 8, 8, 3)      3           ['weight_scaling_10[0][0]']      \n",
      "                                                                                                  \n",
      " activation (Activation)        multiple             0           ['bias_7[1][0]']                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 8, 8, 3)      0           ['bias_10[0][0]']                \n",
      "                                                                                                  \n",
      " weighted_sum (WeightedSum)     (None, 8, 8, 3)      1           ['activation[1][0]',             \n",
      "                                                                  'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,382,663\n",
      "Trainable params: 13,382,663\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 8, 8, 3)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 8, 512)    1536        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " weight_scaling_11 (WeightScali  (None, 8, 8, 512)   0           ['conv2d_9[0][0]']               \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " bias_11 (Bias)                 (None, 8, 8, 512)    512         ['weight_scaling_11[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 8, 8, 512)    0           ['bias_11[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 8, 8, 512)    2359296     ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " weight_scaling_12 (WeightScali  (None, 8, 8, 512)   0           ['conv2d_10[0][0]']              \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " bias_12 (Bias)                 (None, 8, 8, 512)    512         ['weight_scaling_12[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 8, 8, 512)    0           ['bias_12[0][0]']                \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 4, 4, 3)     0           ['input_3[0][0]']                \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 8, 8, 512)    2359296     ['leaky_re_lu_9[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 4, 4, 512)    1536        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " weight_scaling_13 (WeightScali  (None, 8, 8, 512)   0           ['conv2d_11[0][0]']              \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " weight_scaling (WeightScaling)  (None, 4, 4, 512)   0           ['conv2d[1][0]']                 \n",
      "                                                                                                  \n",
      " bias_13 (Bias)                 (None, 8, 8, 512)    512         ['weight_scaling_13[0][0]']      \n",
      "                                                                                                  \n",
      " bias (Bias)                    (None, 4, 4, 512)    512         ['weight_scaling[1][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 8, 8, 512)    0           ['bias_13[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 4, 4, 512)    0           ['bias[1][0]']                   \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 4, 4, 512)   0           ['leaky_re_lu_10[0][0]']         \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " weighted_sum_1 (WeightedSum)   (None, 4, 4, 512)    1           ['leaky_re_lu[1][0]',            \n",
      "                                                                  'average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " minibatch_stdev (MinibatchStde  (None, 4, 4, 513)   0           ['weighted_sum_1[0][0]']         \n",
      " v)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 4, 4, 512)    2363904     ['minibatch_stdev[2][0]']        \n",
      "                                                                                                  \n",
      " weight_scaling_1 (WeightScalin  (None, 4, 4, 512)   0           ['conv2d_1[2][0]']               \n",
      " g)                                                                                               \n",
      "                                                                                                  \n",
      " bias_1 (Bias)                  (None, 4, 4, 512)    512         ['weight_scaling_1[2][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 4, 4, 512)    0           ['bias_1[2][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 1, 1, 512)    4194304     ['leaky_re_lu_1[2][0]']          \n",
      "                                                                                                  \n",
      " weight_scaling_2 (WeightScalin  (None, 1, 1, 512)   0           ['conv2d_2[2][0]']               \n",
      " g)                                                                                               \n",
      "                                                                                                  \n",
      " bias_2 (Bias)                  (None, 1, 1, 512)    512         ['weight_scaling_2[2][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 1, 1, 512)    0           ['bias_2[2][0]']                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 512)          0           ['leaky_re_lu_2[2][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            512         ['flatten[2][0]']                \n",
      "                                                                                                  \n",
      " weight_scaling_3 (WeightScalin  (None, 1)           0           ['dense[2][0]']                  \n",
      " g)                                                                                               \n",
      "                                                                                                  \n",
      " bias_3 (Bias)                  (None, 1)            1           ['weight_scaling_3[2][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,283,458\n",
      "Trainable params: 11,283,458\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "Epoch 1/50\n",
      "270/270 [==============================] - 34s 109ms/step - d_loss: -0.8802 - g_loss: 0.9714\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 29s 108ms/step - d_loss: -0.7269 - g_loss: 1.2017\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 29s 109ms/step - d_loss: -0.3703 - g_loss: 0.7947\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 29s 109ms/step - d_loss: -0.1996 - g_loss: 0.6003\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 29s 108ms/step - d_loss: -0.1621 - g_loss: 0.4498\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 29s 109ms/step - d_loss: -0.0646 - g_loss: 0.3582\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 29s 109ms/step - d_loss: -0.0771 - g_loss: 0.2222\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 29s 109ms/step - d_loss: -0.0353 - g_loss: 0.3017\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 29s 109ms/step - d_loss: 0.0121 - g_loss: 0.2450\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 29s 108ms/step - d_loss: -0.0160 - g_loss: 0.2180\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 29s 108ms/step - d_loss: 8.1636e-04 - g_loss: 0.2041\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 29s 109ms/step - d_loss: 0.0083 - g_loss: 0.2345\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 29s 109ms/step - d_loss: 0.0024 - g_loss: 0.1993\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 29s 109ms/step - d_loss: 0.0038 - g_loss: 0.1946\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 29s 109ms/step - d_loss: -0.0053 - g_loss: 0.2520\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 29s 109ms/step - d_loss: -0.0090 - g_loss: 0.2027\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 29s 108ms/step - d_loss: -0.0130 - g_loss: 0.1759\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 29s 109ms/step - d_loss: -0.0180 - g_loss: 0.2065\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 29s 109ms/step - d_loss: 0.0060 - g_loss: 0.1748\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 29s 108ms/step - d_loss: -0.0095 - g_loss: 0.2004\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 29s 108ms/step - d_loss: -0.0145 - g_loss: 0.1973\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 29s 109ms/step - d_loss: -0.0182 - g_loss: 0.1666\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 29s 108ms/step - d_loss: 0.0014 - g_loss: 0.1649\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 29s 108ms/step - d_loss: -0.0091 - g_loss: 0.2116\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 29s 109ms/step - d_loss: -0.0035 - g_loss: 0.1630\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 29s 108ms/step - d_loss: -0.0159 - g_loss: 0.1953\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 29s 108ms/step - d_loss: -0.0107 - g_loss: 0.1923\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 29s 109ms/step - d_loss: -0.0094 - g_loss: 0.1582\n",
      "Epoch 29/50\n",
      "248/270 [==========================>...] - ETA: 2s - d_loss: -0.0154 - g_loss: 0.1974"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train faded-in / stabilized generators and discriminators\n",
    "for n_depth in range(1, 6):\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"[INFO] Fading phase for {n_depth}\")\n",
    "    # Set current level(depth)\n",
    "    pgan.n_depth = n_depth\n",
    "\n",
    "    new_dim=2**(n_depth)*4\n",
    "    new_dim=(new_dim,new_dim)\n",
    "\n",
    "    ##dataset redefinition\n",
    "    BS=BS_list[n_depth]\n",
    "    ts = len(train_imgs) // BS\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "\n",
    "    train_dataset = (train_dataset.shuffle(1024).map(lambda x: resize(x,new_dim)).cache().repeat().batch(BS).prefetch(AUTOTUNE)\n",
    "    )\n",
    "    #enlarge network\n",
    "\n",
    "    pgan.fade_in_generator()\n",
    "    pgan.fade_in_discriminator()\n",
    "\n",
    "    # Draw fade in generator and discriminator\n",
    "    tf.keras.utils.plot_model(pgan.generator, to_file=opj(checkpoint_path,f'generator_{pgan.n_depth}.png'), show_shapes=True)\n",
    "    tf.keras.utils.plot_model(pgan.discriminator, to_file=opj(checkpoint_path,f'discriminator_{pgan.n_depth}.png'), show_shapes=True)\n",
    "\n",
    "    pgan.compile(\n",
    "      d_optimizer=discriminator_optimizer,\n",
    "      g_optimizer=generator_optimizer,\n",
    "    )\n",
    "    # Train fade in generator and discriminator\n",
    "    pgan.fit(train_dataset, steps_per_epoch=ts, epochs=EPOCHS_PER_RES, callbacks=callbacks)\n",
    "\n",
    "    pgan.generator.save_weights(opj(checkpoint_path, f\"generator_ndepth_{n_depth}_weights_cifar.h5\"))\n",
    "    pgan.discriminator.save_weights(opj(checkpoint_path, f\"discriminator_ndepth_{n_depth}_weights_cifar.h5\"))\n",
    "\n",
    "    try:\n",
    "        pgan.save_weights(opj(checkpoint_path, f\"checkpoint_path_ndepth_{n_depth}_weights_cifar.ckpt\"),save_format=\"tf\")\n",
    "    except:\n",
    "        print(\"[WARNING] Could not save weights!\")\n",
    "\n",
    "\n",
    "    print(f\"[INFO] Stabilizing phase for {n_depth}\")\n",
    "    pgan.stabilize_generator()\n",
    "    pgan.stabilize_discriminator()\n",
    "\n",
    "    # Draw fade in generator and discriminator\n",
    "    tf.keras.utils.plot_model(pgan.generator, to_file=opj(checkpoint_path,f'generator_{pgan.n_depth}_stabilized.png'), show_shapes=True)\n",
    "    tf.keras.utils.plot_model(pgan.discriminator, to_file=opj(checkpoint_path,f'discriminator_{pgan.n_depth}_stabilized.png'), show_shapes=True)\n",
    "\n",
    "    pgan.compile(d_optimizer=discriminator_optimizer,g_optimizer=generator_optimizer,)\n",
    "    # Train stabilized generator and discriminator\n",
    "    pgan.fit(train_dataset, steps_per_epoch = ts, epochs = EPOCHS_PER_RES, callbacks=callbacks)\n",
    "    pgan.generator.save_weights(opj(checkpoint_path, f\"generator_stabilized_ndepth_{n_depth}_weights_cifar.h5\"))\n",
    "    pgan.discriminator.save_weights(opj(checkpoint_path, f\"discriminator_stabilized_ndepth_{n_depth}_weights_cifar.h5\"))\n",
    "\n",
    "    try:\n",
    "        pgan.save_weights(opj(checkpoint_path, f\"checkpoint_path_stabilized_ndepth_{n_depth}_weights_cifar.ckpt\"), save_format=\"tf\")\n",
    "    except:\n",
    "        print(\"[WARNING] Could not save weights!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e178716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
