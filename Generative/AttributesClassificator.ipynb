{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ba09281",
   "metadata": {},
   "source": [
    "## Attributes Classificator\n",
    "\n",
    "In this notebook I will try to classify all the attributes present in a face.\n",
    "This could be useful to use the attributes as condition in input of conditional models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3771e93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from classes.Architectures import VGGNetLike\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join as opj\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from imutils import paths\n",
    "from tensorflow.data import AUTOTUNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e0133477-2090-45e0-bdca-7a82e3335f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">CelebA_Attribute_Prediciton</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/matteoferrante/TorVergataExperiment-Generative\" target=\"_blank\">https://wandb.ai/matteoferrante/TorVergataExperiment-Generative</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/matteoferrante/TorVergataExperiment-Generative/runs/3xzprwrt\" target=\"_blank\">https://wandb.ai/matteoferrante/TorVergataExperiment-Generative/runs/3xzprwrt</a><br/>\n",
       "                Run data is saved locally in <code>/home/matteo/NeuroGEN/TorVergataExperiments/Generative/wandb/run-20211130_154833-3xzprwrt</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(3xzprwrt)</h1><iframe src=\"https://wandb.ai/matteoferrante/TorVergataExperiment-Generative/runs/3xzprwrt\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f5221ec18e0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_dir=r\"/home/matteo/NeuroGEN/Dataset/Img/img_align_celeba\"\n",
    "anno_dir=r\"/home/matteo/NeuroGEN/Dataset/Anno/list_attr_celeba.csv\"\n",
    "#other important definitions\n",
    "\n",
    "EPOCHS=50\n",
    "BS=64\n",
    "INIT_LR=1e-4\n",
    "\n",
    "config={}\n",
    "config[\"epochs\"]=EPOCHS\n",
    "config[\"BS\"]=BS\n",
    "config[\"init_lr\"]=INIT_LR\n",
    "\n",
    "wandb.init(project=\"TorVergataExperiment-Generative\",config=config,name=\"CelebA_Attribute_Prediciton\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b541e",
   "metadata": {},
   "source": [
    "## Load data and indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b6922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(anno_dir,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3ebc1637-75b1-48f5-8c5f-60175cd42572",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load_images(imagePath,attr):\n",
    "\n",
    "    #attr=df.iloc[idx].drop(\"image_id\",axis=1).values\n",
    "    # read the image from disk, decode it, resize it, and scale the\n",
    "    # pixels intensities to the range [0, 1]\n",
    "    image = tf.io.read_file(imagePath)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (128, 128)) / 255.0\n",
    "\n",
    "    #eventually load other information like attributes here\n",
    "    \n",
    "    # return the image and the extra info\n",
    "    \n",
    "    \n",
    "    return image,attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e0ed010-83ab-4b95-a277-0e950176e06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading image paths...\n",
      "[TRAINING]\t 138545\n",
      "[VALIDATION]\t 17318\n",
      "[TEST]\t\t 17319\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading image paths...\")\n",
    "imagePaths = list(paths.list_images(images_dir))\n",
    "\n",
    "\n",
    "train_len=int(0.8*len(imagePaths))\n",
    "val_len=int(0.1*len(imagePaths))\n",
    "test_len=int(0.1*len(imagePaths))\n",
    "\n",
    "train_imgs=imagePaths[:train_len]                                #      80% for training\n",
    "val_imgs=imagePaths[train_len:train_len+val_len]                 #      10% for validation\n",
    "test_imgs=imagePaths[train_len+val_len:]                         #      10% for testing\n",
    "\n",
    "train_idxs=[int(i.split(\"/\")[-1].split(\".jpg\")[0])-1 for i in train_imgs]\n",
    "val_idxs=[int(i.split(\"/\")[-1].split(\".jpg\")[0])-1 for i in val_imgs]\n",
    "test_idxs=[int(i.split(\"/\")[-1].split(\".jpg\")[0])-1 for i in test_imgs]\n",
    "\n",
    "train_attr=[df.iloc[idx].drop(\"image_id\").values for idx in train_idxs]\n",
    "val_attr=[df.iloc[idx].drop(\"image_id\").values for idx in val_idxs]\n",
    "test_attr=[df.iloc[idx].drop(\"image_id\").values for idx in test_idxs]\n",
    "\n",
    "\n",
    "print(f\"[TRAINING]\\t {len(train_imgs)}\\n[VALIDATION]\\t {len(val_imgs)}\\n[TEST]\\t\\t {len(test_imgs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1a57bc12-698a-466b-be53-97efc953f106",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attr=np.array(train_attr).astype(\"int\")\n",
    "val_attr=np.array(val_attr).astype(\"int\")\n",
    "test_attr=np.array(test_attr).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "381321c2-8e78-4d32-8012-64d6a880ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING \n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_imgs,train_attr))\n",
    "train_dataset = (train_dataset\n",
    "    .shuffle(1024)\n",
    "    .map(load_images)\n",
    "    .cache()\n",
    "    .repeat()\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "ts=len(train_imgs)//BS\n",
    "\n",
    "##VALIDATION\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_imgs,val_attr))\n",
    "val_dataset = (val_dataset\n",
    "    .shuffle(1024)\n",
    "    .map(load_images)\n",
    "    .cache()\n",
    "    .repeat()\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "vs=len(val_imgs)//BS\n",
    "\n",
    "## TEST\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_imgs,test_attr))\n",
    "test_dataset = (test_dataset\n",
    "    .shuffle(1024)\n",
    "    .map(lambda x,y:load_images(x,y), num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "80f78519-e8ef-4cc3-88c6-28682d6ec7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 128, 128, 3)\n",
      "(64, 40)\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dataset:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f723c380-e9b7-4f6e-85e0-f86db8bed4ba",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "429d0768",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=VGGNetLike((128,128,3),40)\n",
    "\n",
    "\n",
    "opt=tf.keras.optimizers.Adam(INIT_LR)\n",
    "callbacks=[WandbCallback()]\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=opt,metrics=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c607904a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGGNetLike_Classificator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 8, 8, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              134221824 \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 40)                163880    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 149,247,976\n",
      "Trainable params: 149,247,976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb0745e",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef63bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   6/2164 [..............................] - ETA: 6:09 - loss: -152.2298 - accuracy: 0.0154   WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0697s vs `on_train_batch_end` time: 0.1002s). Check your callbacks.\n",
      "2164/2164 [==============================] - 630s 290ms/step - loss: -338.8349 - accuracy: 0.0062\n",
      "Epoch 2/50\n",
      "2164/2164 [==============================] - 602s 278ms/step - loss: -370.3544 - accuracy: 0.0037\n",
      "Epoch 3/50\n",
      "2164/2164 [==============================] - 622s 288ms/step - loss: -373.7160 - accuracy: 0.0054\n",
      "Epoch 4/50\n",
      "2164/2164 [==============================] - 620s 287ms/step - loss: -373.6825 - accuracy: 0.0053\n",
      "Epoch 5/50\n",
      "2164/2164 [==============================] - 625s 289ms/step - loss: -373.6770 - accuracy: 0.0053\n",
      "Epoch 6/50\n",
      "2164/2164 [==============================] - 624s 289ms/step - loss: -373.7118 - accuracy: 0.0054\n",
      "Epoch 7/50\n",
      "2164/2164 [==============================] - 622s 288ms/step - loss: -373.7362 - accuracy: 0.0053\n",
      "Epoch 8/50\n",
      "2164/2164 [==============================] - 623s 288ms/step - loss: -373.7488 - accuracy: 0.0053\n",
      "Epoch 9/50\n",
      "2164/2164 [==============================] - 621s 287ms/step - loss: -373.7485 - accuracy: 0.0053\n",
      "Epoch 10/50\n",
      "1511/2164 [===================>..........] - ETA: 3:08 - loss: -373.8154 - accuracy: 0.0053"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset,epochs=EPOCHS,steps_per_epoch=ts,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d79a9-4d0a-46e6-88e8-2e35ce42e6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
