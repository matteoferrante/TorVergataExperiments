{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22632d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import argparse\n",
    "from classes.PGGAN import PGGAN\n",
    "from utils.callbacks import WandbImagesPGGAN\n",
    "import wandb\n",
    "import tensorflow.keras as keras\n",
    "from os.path import join as opj\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d42c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e4950a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<wandb.sdk.wandb_run.Run at 0x7f5663888100>"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/matteoferrante/TorVergataExperiment-Generative/runs/23od6noo\" target=\"_blank\">earthy-wood-457</a></strong> to <a href=\"https://wandb.ai/matteoferrante/TorVergataExperiment-Generative\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "wandb.login()\n",
    "\n",
    "checkpoint_path= \"models/PGGAN_celebA\"\n",
    "config={\"dataset\":\"celebA\", \"type\":\"PG-GAN\"}\n",
    "config[\"nota\"]=\"DGX\"\n",
    "wandb.init(project=\"TorVergataExperiment-Generative\",config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e37637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BS_list = [512,512,256,128,64,32]\n",
    "\n",
    "BS=BS_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a767f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NOISE_DIM = 256\n",
    "# Set the number of batches, epochs and steps for trainining.\n",
    "# Look 800k images(16x50x1000) per each lavel\n",
    "EPOCHS_PER_RES = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ffe144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(imagePath):\n",
    "    # read the image from disk, decode it, resize it, and scale the\n",
    "    # pixels intensities to the range [0, 1]\n",
    "    image = tf.io.read_file(imagePath)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (128, 128)) / 255.0\n",
    "\n",
    "    #eventually load other information like attributes here\n",
    "    \n",
    "    # return the image and the extra info\n",
    "    \n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab668be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INIT\n",
    "\n",
    "def resize(img,target_size=(4,4)):\n",
    "    return tf.image.resize(img,target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82308dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] loading image paths...\")\n",
    "imagePaths = list(paths.list_images(images_dir))\n",
    "\n",
    "\n",
    "train_len=int(0.8*len(imagePaths))\n",
    "val_len=int(0.1*len(imagePaths))\n",
    "test_len=int(0.1*len(imagePaths))\n",
    "\n",
    "train_imgs=imagePaths[:train_len]                                #      80% for training\n",
    "val_imgs=imagePaths[train_len:train_len+val_len]                 #      10% for validation\n",
    "test_imgs=imagePaths[train_len+val_len:]                         #      10% for testing\n",
    "\n",
    "print(f\"[TRAINING]\\t {len(train_imgs)}\\n[VALIDATION]\\t {len(val_imgs)}\\n[TEST]\\t\\t {len(test_imgs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b809eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import argparse\n",
    "from classes.PGGAN import PGGAN\n",
    "from utils.callbacks import WandbImagesPGGAN\n",
    "import wandb\n",
    "import tensorflow.keras as keras\n",
    "from os.path import join as opj\n",
    "from wandb.keras import WandbCallback\n",
    "from imutils import paths\n",
    "\n",
    "from imutils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "474d7572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import argparse\n",
    "from classes.PGGAN import PGGAN\n",
    "from utils.callbacks import WandbImagesPGGAN\n",
    "import wandb\n",
    "import tensorflow.keras as keras\n",
    "from os.path import join as opj\n",
    "from wandb.keras import WandbCallback\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49a12e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] loading image paths...\")\n",
    "imagePaths = list(paths.list_images(images_dir))\n",
    "\n",
    "\n",
    "train_len=int(0.8*len(imagePaths))\n",
    "val_len=int(0.1*len(imagePaths))\n",
    "test_len=int(0.1*len(imagePaths))\n",
    "\n",
    "train_imgs=imagePaths[:train_len]                                #      80% for training\n",
    "val_imgs=imagePaths[train_len:train_len+val_len]                 #      10% for validation\n",
    "test_imgs=imagePaths[train_len+val_len:]                         #      10% for testing\n",
    "\n",
    "print(f\"[TRAINING]\\t {len(train_imgs)}\\n[VALIDATION]\\t {len(val_imgs)}\\n[TEST]\\t\\t {len(test_imgs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57d4f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wandb.login()\n",
    "\n",
    "checkpoint_path= \"models/PGGAN_celebA\"\n",
    "config={\"dataset\":\"celebA\", \"type\":\"PG-GAN\"}\n",
    "config[\"nota\"]=\"DGX\"\n",
    "wandb.init(project=\"TorVergataExperiment-Generative\",config=config)\n",
    "\n",
    "images_dir=r\"/home/matteo/NeuroGEN/Dataset/Img/img_align_celeba\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
