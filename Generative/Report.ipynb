{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0edd7a90",
   "metadata": {},
   "source": [
    "## Report Notebook\n",
    "\n",
    "This is just a notebook to compare the results of the generative models on several datasets, saving the results on wandb as tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cb93c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join as opj\n",
    "from classes.VAE import VAE\n",
    "from classes.VQVAE import VQVAE, VQVAE2\n",
    "from classes.GAN import GAN\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.data import AUTOTUNE\n",
    "from imutils import paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df622998",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "\n",
    "BS=128\n",
    "\n",
    "#set the second GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(os.environ.get(\"CUDA_VISIBLE_DEVICES\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e53e60e",
   "metadata": {},
   "source": [
    "### Models path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b54831fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_path=\"models/vae\"\n",
    "vqvae_path=\"models/vqvae_celeba\"\n",
    "vqvae2_path=\"models/vqvae2_celeba\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3495a374",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Impossibile trovare il percorso specificato: 'models/vqvae2_celeba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12536/2308200153.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvqvae2_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Impossibile trovare il percorso specificato: 'models/vqvae2_celeba'"
     ]
    }
   ],
   "source": [
    "os.listdir(vqvae2_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd735b5",
   "metadata": {},
   "source": [
    "## CelebA comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a5686ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir=r\"C:\\Users\\matte\\Dataset\\tor_vergata\\Dataset\\Img\\img_align_celeba\" #local\n",
    "#images_dir=r\"/home/matteo/NeuroGEN/Dataset/Img/img_align_celeba\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cedb019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(imagePath):\n",
    "    # read the image from disk, decode it, resize it, and scale the\n",
    "    # pixels intensities to the range [0, 1]\n",
    "    image = tf.io.read_file(imagePath)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (128, 128)) / 255.0\n",
    "\n",
    "    #eventually load other information like attributes here\n",
    "    \n",
    "    # return the image and the extra info\n",
    "    \n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "256b4d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading image paths...\n",
      "[TRAINING]\t 113455\n",
      "[VALIDATION]\t 14181\n",
      "[TEST]\t\t 14183\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading image paths...\")\n",
    "imagePaths = list(paths.list_images(images_dir))\n",
    "\n",
    "\n",
    "train_len=int(0.8*len(imagePaths))\n",
    "val_len=int(0.1*len(imagePaths))\n",
    "test_len=int(0.1*len(imagePaths))\n",
    "\n",
    "train_imgs=imagePaths[:train_len]                                #      80% for training\n",
    "val_imgs=imagePaths[train_len:train_len+val_len]                 #      10% for validation\n",
    "test_imgs=imagePaths[train_len+val_len:]                         #      10% for testing\n",
    "\n",
    "print(f\"[TRAINING]\\t {len(train_imgs)}\\n[VALIDATION]\\t {len(val_imgs)}\\n[TEST]\\t\\t {len(test_imgs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "269fefb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING \n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "train_dataset = (train_dataset\n",
    "    .map(load_images, num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .repeat()\n",
    "    .batch(BS)\n",
    "    .shuffle(1024)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "ts=len(train_imgs)//BS\n",
    "\n",
    "##VALIDATION\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(val_imgs)\n",
    "val_dataset = (val_dataset\n",
    "    .map(load_images, num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .repeat()\n",
    "    .shuffle(1024)\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "vs=len(val_imgs)//BS\n",
    "\n",
    "## TEST\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
    "test_dataset = (test_dataset\n",
    "    .map(load_images, num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .shuffle(1024)\n",
    "    .batch(BS)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c924290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
