from numpy.random import randint

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import *
from tensorflow.keras.models import Model
import numpy as np


class cGAN(keras.Model):

    """
    class for conditional Generative extending keras.Model

    The idea of conditional GANs is to pass a condition to the generator it has to learn p(X|C) where is X is the latent space
    to generate input of specific cases.
    conditions are passed as embedding both to the generator and the discriminator to introduce this information and the labels
    are generated in two step as in usual Generative cases:

    in the first step we train the discriminator with both real and fakes images generated by the generator.

    So we feed our discriminator with r (real images) with real conditions and f (fake images with random conditions)
    and labels 0 for fake and 1 for real

    In the second step we will train the generator using the Generative approach generating fake images with random conditions
    with measleading labels (1 even if are fake images). In this step we update just the weights of the generator

    """
    def __init__(self, latent_dim,dims=(28,28,1),n_classes=10,emb_dim=50):

        """

        :param latent_dim: int, dimension of the latent space
        :param dims: tuple, shape of the images
        :param n_classes: int, number of classes
        :param emb_dim: int, dimension of the embedding space
        """
        super().__init__()
        self.discriminator = self.build_discriminator(dims,n_classes,emb_dim)
        self.generator = self.build_generator(latent_dim,n_classes,emb_dim)
        self.gan=self.build_gan()
        self.latent_dim = latent_dim
        self.n_classes=n_classes
        self.emb_dim=emb_dim


    def compile(self, d_optimizer=tf.keras.optimizers.Adam(3e-4), g_optimizer=tf.keras.optimizers.Adam(3e-4), loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True),d_accuracy=tf.keras.metrics.Accuracy()):
        """
        method to compile all modules of this model

        :param d_optimizer: optimizer for discriminator
        :param g_optimizer: optimizer for generator
        :param loss_fn:  loss function to use for discriminator and gan
        :param d_accuracy: metric to measure discriminator performances
        """

        super(cGAN, self).compile(run_eagerly=True)
        self.d_optimizer = d_optimizer
        self.g_optimizer = g_optimizer
        self.loss_fn = loss_fn
        self.d_accuracy=d_accuracy

    def call(self, inputs, training=None, mask=None):
        return self.gan(inputs)



    def train_step(self, data):
        """
        Training step of .fit method.
        It trains the discriminator using a concatenation of real and fake images labelled as 0 and 1 respectively.
        images are coupled with the conditions that are mapped to an embedding space in order to reproduce a specific label case

        conditions (that are basically labels ie 0,1,2..9 in the mnist dataset) are passed both to a generator and a discriminator.
        The labels for the discriminator are generated as in the uncodinationed Generative cases.

        In a second step it train the gan (generator->discriminator) with frozen discriminator weights and images
        generated from noise from generator, using misleading labels (images are fake but labels are 0, to let the
        generator learn how to foolish the discriminator

        :param data: data used for training (i.e the real images)
        :return: a dict of metrics including g_loss, d_loss and d_accuracy
        """

        x,conditions=data

        conditions=tf.cast(conditions,dtype=tf.int32)  #just to be coherent with random_conditions

        batch_size = tf.shape(x)[0]

        #fake 1, real 0


        ## step 1 train the discriminator with real and fake imgs

        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))


        # Decode them to fake images
        random_conditions = tf.random.uniform(shape=[batch_size,],minval=0,maxval=self.n_classes,dtype=tf.int32)
        generated_images = self.generator([random_latent_vectors,random_conditions])

        # Combine them with real images

        combined_images = tf.concat([generated_images, x], axis=0)
        combined_conditions=tf.concat([random_conditions,conditions],axis=0)

        # Assemble labels discriminating real from fake images
        labels = tf.concat(
            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0
        )

        # Add random noise to the labels - important trick!
        labels += 0.05 * tf.random.uniform(labels.shape)




        with tf.GradientTape() as tape:

            y_pred=self.discriminator([combined_images,combined_conditions])

            d_loss=self.loss_fn(labels,y_pred)
            d_acc=self.d_accuracy(tf.round(labels),tf.round(y_pred))

        grads=tape.gradient(d_loss,self.discriminator.trainable_weights)
        self.d_optimizer.apply_gradients(zip(grads,self.discriminator.trainable_weights))


        ## step 2. try to foolish the discriminator with fake images and backpropagate to generator

        random_latent_vectors=tf.random.normal(shape=(batch_size,self.latent_dim))
        random_conditions = randint(0, self.n_classes, batch_size)  #generate conditions

        misleading_labels=tf.zeros((batch_size,1))

        with tf.GradientTape() as tape:

            y_pred=self.discriminator([self.generator([random_latent_vectors,random_conditions]),random_conditions])
            g_loss=self.loss_fn(misleading_labels,y_pred)

        grads=tape.gradient(g_loss,self.generator.trainable_weights)
        self.g_optimizer.apply_gradients(zip(grads,self.generator.trainable_weights))


        return {"d_loss":d_loss,"g_loss":g_loss, "d_acc":d_acc}

    def build_discriminator(self,dims,n_classes,emb_dim):
        """

        :param dims: dimension of the input images
        :param n_classes: number of possible conditions
        :param emb_dim: dimension of the embedding space
        :return: keras model of discriminator
        """

        ## label input

        in_label=Input(shape=(1,))                  #input for condition the class
        li=Embedding(n_classes,emb_dim)(in_label)              #li stands for label input
        li=Dense(np.prod(dims))(li)
        li = Reshape((dims[0], dims[1], 1))(li)        #produce image compatible shapes

        #image input
        in_image = Input(shape=dims)

        merge = Concatenate()([in_image, li])           #concatenate into a multichannel image

        ## discriminator

        x=Conv2D(128, (3, 3), strides=(2, 2), padding="same")(merge)
        x=LeakyReLU(alpha=0.2)(x)
        x=Conv2D(128, (3, 3), strides=(2, 2), padding="same")(x)
        x=LeakyReLU(alpha=0.2)(x)
        x=GlobalMaxPooling2D()(x)
        x=Dense(1)(x)

        model = Model([in_image, in_label], x,name="discriminator")

        return model


    def build_generator(self,latent_dim,n_classes,emb_dim):

        """
        :param dims: dimension of the input images
        :param n_classes: number of possible conditions
        :param emb_dim: dimension of the embedding space
        :return: keras model of generator
        """

        ## label input

        in_label=Input(shape=(1,))                               #input for condition the class
        li=Embedding(n_classes,emb_dim)(in_label)                #li stands for label input
        li=Dense(7*7)(li)
        li = Reshape((7, 7, 1))(li)                              #produce starting image compatible shapes

        #latent input

        in_latent=Input(shape=(latent_dim,))

        gen=Dense(7 * 7 * 64)(in_latent)
        gen=LeakyReLU(alpha=0.2)(gen)
        gen=Reshape((7, 7, 64))(gen)

        merge = Concatenate()([gen, li])

        x=Conv2DTranspose(64, (4, 4), strides=(2, 2), padding="same")(merge)
        x=LeakyReLU(alpha=0.2)(x)
        x=Conv2DTranspose(64, (4, 4), strides=(2, 2), padding="same")(x)
        x=LeakyReLU(alpha=0.2)(x)
        x=Conv2D(1, (7, 7), padding="same", activation="sigmoid")(x)

        model = Model([in_latent, in_label], x,name="generator")

        return model

    def build_gan(self):

        """
        Generative MODEL


        WARNING: If is intended to work with gan.train_on_batch() is needed to uncomment d_model.trainable=False

        :return: keras Generative model
        """

        g_model=self.generator
        d_model=self.discriminator

        #d_model.trainable=False   ##decomment if gan.train_on_batch is needed

        gen_noise,gen_label=g_model.input
        gen_output=g_model.output

        gan_output = d_model([gen_output, gen_label])

        model = Model([gen_noise, gen_label], gan_output,name="cGAN")

        return model


