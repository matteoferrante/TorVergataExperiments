{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd2ae4d",
   "metadata": {},
   "source": [
    "## Train GAN on CelebA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c541f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from classes.GAN import GAN\n",
    "from utils.callbacks import WandbImagesVAE, SaveGeneratorWeights, SaveVAEWeights, WandbVAECallback, WandbImagesGAN, \\\n",
    "    SaveGANWeights\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcc3169",
   "metadata": {},
   "source": [
    "### Model definition\n",
    "And initial configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b89725",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "\n",
    "\n",
    "encoder_architecture=[(1,64),(1,128),(1,256),(1,384),(1,512)]\n",
    "decoder_architecture=[(1,512),(1,384),(1,256),(1,128),(1,64)]\n",
    "\n",
    "g=GAN((128,128,3),\n",
    "      latent_dim=512,\n",
    "      encoder_architecture=encoder_architecture,\n",
    "      decoder_architecture=decoder_architecture)\n",
    "\n",
    "\n",
    "config={\"dataset\":\"celebA\", \"type\":\"GAN\",\"encoder_architecture\":encoder_architecture,\"decoder_architecture\":decoder_architecture}\n",
    "config.update(g.get_dict())\n",
    "\n",
    "\n",
    "images_dir=r\"/home/matteo/NeuroGEN/Dataset/Img/img_align_celeba\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e215a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#other important definitions\n",
    "\n",
    "EPOCHS=50\n",
    "BS=128\n",
    "INIT_LR=1e-4\n",
    "\n",
    "config[\"epochs\"]=EPOCHS\n",
    "config[\"BS\"]=BS\n",
    "config[\"init_lr\"]=INIT_LR\n",
    "\n",
    "wandb.init(project=\"TorVergataExperiment-Generative\",config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30181726",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc70a73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(imagePath):\n",
    "    # read the image from disk, decode it, resize it, and scale the\n",
    "    # pixels intensities to the range [0, 1]\n",
    "    image = tf.io.read_file(imagePath)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (128, 128)) / 255.0\n",
    "\n",
    "    # eventually load other information like attributes here\n",
    "\n",
    "    # return the image and the extra info\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "print(\"[INFO] loading image paths...\")\n",
    "imagePaths = list(paths.list_images(images_dir))\n",
    "\n",
    "\n",
    "train_len=int(0.8*len(imagePaths))\n",
    "val_len=int(0.1*len(imagePaths))\n",
    "test_len=int(0.1*len(imagePaths))\n",
    "\n",
    "train_imgs=imagePaths[:train_len]                                #      80% for training\n",
    "val_imgs=imagePaths[train_len:train_len+val_len]                 #      10% for validation\n",
    "test_imgs=imagePaths[train_len+val_len:]                         #      10% for testing\n",
    "\n",
    "print(f\"[TRAINING]\\t {len(train_imgs)}\\n[VALIDATION]\\t {len(val_imgs)}\\n[TEST]\\t\\t {len(test_imgs)}\")\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
    "train_dataset = (train_dataset\n",
    "    .shuffle(1024)\n",
    "    .map(load_images)\n",
    "    .cache()\n",
    "    .repeat()\n",
    "    .batch(BS)\n",
    ")\n",
    "\n",
    "ts=len(train_imgs)//BS\n",
    "\n",
    "##VALIDATION\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(val_imgs)\n",
    "val_dataset = (val_dataset\n",
    "    .shuffle(1024)\n",
    "    .map(load_images)\n",
    "    .cache()\n",
    "    .repeat()\n",
    "    .batch(BS)\n",
    ")\n",
    "\n",
    "vs=len(val_imgs)//BS\n",
    "\n",
    "## TEST\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
    "test_dataset = (test_dataset\n",
    "    .shuffle(1024)\n",
    "    .map(load_images)\n",
    "    .cache()\n",
    "    .batch(BS)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316d28d6",
   "metadata": {},
   "source": [
    "## Compile\n",
    "And set callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f4bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models/gan\",exist_ok=True)\n",
    "model_check=SaveGANWeights(filepath=\"models/gan\")\n",
    "\n",
    "g.compile()\n",
    "\n",
    "\n",
    "\n",
    "wb=WandbCallback()\n",
    "\n",
    "callbacks=[\n",
    "    WandbImagesGAN(target_shape=(128,128,3)),\n",
    "    wb,\n",
    "    model_check,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d27f82",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda939fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fit(train_dataset,validation_data=test_dataset,steps_per_epoch=ts,validation_steps=vs,epochs=EPOCHS,callbacks=callbacks)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
